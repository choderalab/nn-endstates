{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [23:00:30] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conducting subsequent work with the following platform: CPU\n",
      "conducting subsequent work with the following platform: CPU\n",
      "conducting subsequent work with the following platform: CPU\n"
     ]
    }
   ],
   "source": [
    "from coddiwomple.openmm.integrators import OMMLI\n",
    "from coddiwomple.openmm.propagators import OMMBIP\n",
    "from coddiwomple.openmm.reporters import OpenMMReporter\n",
    "from openmmtools.states import ThermodynamicState, SamplerState\n",
    "from simtk import unit\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tqdm\n",
    "import mdtraj.utils as mdtrajutils\n",
    "import mdtraj as md\n",
    "import torch\n",
    "import torchani\n",
    "from openmmtools.constants import kB\n",
    "\n",
    "from openmmtools import cache, utils\n",
    "from perses.dispersed.utils import check_platform, configure_platform\n",
    "cache.global_context_cache.platform = configure_platform(utils.get_fastest_platform().getName())\n",
    "atomic_num_to_symbol_dict = {1: 'H', 6: 'C', 7: 'N', 8: 'O'}\n",
    "mass_dict_in_daltons = {'H': 1.0, 'C': 12.0, 'N': 14.0, 'O': 16.0}\n",
    "\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "#####Instantiate Logger#####\n",
    "logging.basicConfig(level = logging.NOTSET)\n",
    "_logger = logging.getLogger(\"hybrid_propagators\")\n",
    "_logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANI1_force_and_energy(object):\n",
    "    # some class attributes\n",
    "    mass_unit = unit.dalton\n",
    "    distance_unit = unit.nanometers\n",
    "    time_unit = unit.femtoseconds\n",
    "    energy_unit = unit.kilojoules_per_mole\n",
    "    ani_distance_unit = unit.angstroms\n",
    "    hartree_to_kJ_per_mole = 2625.499638\n",
    "    ani_energy_unit = hartree_to_kJ_per_mole * energy_unit\n",
    "    nm_to_angstroms = 10.\n",
    "    angstroms_to_nm = 1e-1\n",
    "\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 atoms,\n",
    "                 platform='cpu',\n",
    "                 temperature=300 * unit.kelvin\n",
    "                 ):\n",
    "\n",
    "        \"\"\"\n",
    "        Performs energy and force calculations.\n",
    "        Slightly modified code from:\n",
    "            https://gist.github.com/wiederm/7ac5c29e5a0dea9d17ef16dda93fe02d#file-reweighting-py-L42; thanks, Marcus\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: torchani.models object\n",
    "            model from which to compute energies and forces\n",
    "        atoms: str\n",
    "            a string of atoms in the indexed order\n",
    "        platform : str, default 'cpu',\n",
    "            platform on which to initialize the model device\n",
    "        temperature : float * unit.kelvin, default 300 * unit.kelvin\n",
    "            temperature\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.atoms = atoms\n",
    "\n",
    "        self.platform = platform\n",
    "        self.device = torch.device(self.platform)\n",
    "        if self.platform == 'cpu':\n",
    "            torch.set_num_threads(2)\n",
    "        else:\n",
    "            raise Exception(f\"we don't support gpu just yet\")\n",
    "\n",
    "        self.species = self.model.species_to_tensor(atoms).to(self.device).unsqueeze(0)\n",
    "        self.temperature = temperature\n",
    "        self.beta = 1.0 / (kB * temperature)\n",
    "\n",
    "        self.W_shads = []\n",
    "        self.W = []\n",
    "\n",
    "    def minimize(self,\n",
    "                 coords: unit.quantity.Quantity,\n",
    "                 maxiter: int = 1000):\n",
    "        \"\"\"\n",
    "        Minimizes the molecule. Note, we usually don't want to do this given an input structure since they are already distributed i.i.d.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        coords:simtk.unit.quantity.Quantity\n",
    "        maxiter: int\n",
    "            Maximum number of minimization steps performed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coords:simtk.unit.quantity.Quantity\n",
    "        \"\"\"\n",
    "\n",
    "        assert (type(coords) == unit.quantity.Quantity)\n",
    "\n",
    "        x = coords.value_in_unit(unit.angstrom)\n",
    "        self.memory_of_energy = []\n",
    "        print(\"Begin minimizing...\")\n",
    "        f = optimize.minimize(self._target_energy_function, x, method='BFGS',\n",
    "                              jac=True, options={'maxiter': maxiter, 'disp': True})\n",
    "\n",
    "        _logger.critical(f\"Minimization status: {f.success}\")\n",
    "        memory_of_energy = copy.deepcopy(self.memory_of_energy)\n",
    "        self.memory_of_energy = []\n",
    "\n",
    "        return f.x.reshape(-1, 3) * unit.angstrom, memory_of_energy\n",
    "\n",
    "    def calculate_force(self,\n",
    "                        x: unit.quantity.Quantity) -> (unit.quantity.Quantity, unit.quantity.Quantity):\n",
    "        \"\"\"\n",
    "        Given a coordinate set the forces with respect to the coordinates are calculated.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array of floats, unit'd (distance unit)\n",
    "            initial configuration\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        F : float, unit'd\n",
    "        E : float, unit'd\n",
    "        \"\"\"\n",
    "        #assert (type(x) == unit.quantity.Quantity)\n",
    "\n",
    "        coordinates = torch.tensor([x.value_in_unit(unit.angstroms)],\n",
    "                                   requires_grad=True, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        energy_in_hartree = self._calculate_energy(coordinates)\n",
    "\n",
    "        # derivative of E (in kJ/mol) w.r.t. coordinates (in nm)\n",
    "        derivative = torch.autograd.grad((energy_in_hartree).sum(), coordinates)[0]\n",
    "\n",
    "        if self.platform == 'cpu':\n",
    "            F = -1 * derivative[0].numpy()\n",
    "        elif self.platform == 'cuda':\n",
    "            F = - np.array(derivative.cpu())[0]\n",
    "        else:\n",
    "            raise RuntimeError('Platform needs to be specified. Either CPU or CUDA.')\n",
    "\n",
    "        return (F * self.hartree_to_kJ_per_mole * (unit.kilojoule_per_mole / unit.angstrom),\n",
    "                energy_in_hartree.item() * self.hartree_to_kJ_per_mole * unit.kilojoule_per_mole)\n",
    "\n",
    "    def _calculate_energy(self, coordinates: torch.tensor):\n",
    "        \"\"\"\n",
    "        Helpter function to return energies as tensor.\n",
    "        Given a coordinate set the energy is calculated.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        coordinates : torch.tensor\n",
    "            coordinates in angstroms without units attached\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        energy_in_hartree : torch.tensor\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # stddev_in_hartree = torch.tensor(0.0,device = self.device, dtype=torch.float64)\n",
    "        energy_in_hartree = self.model((self.species, coordinates)).energies\n",
    "\n",
    "        return energy_in_hartree\n",
    "\n",
    "    def _target_energy_function(self, x) -> (float, np.array):\n",
    "        \"\"\"\n",
    "        Given a coordinate set (x) the energy is calculated in kJ/mol.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array of floats, unit'd (distance unit)\n",
    "            initial configuration\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        E : float, unitless (in kJ/mol)\n",
    "        F_flat : (len(x) * 3, )-shaped np.array, unitless (in kJ/mol / unit.angstrom)\n",
    "        \"\"\"\n",
    "        x = x.reshape(-1, 3) * unit.angstrom\n",
    "        F, E = self.calculate_force(x)\n",
    "        F_flat = -np.array(F.value_in_unit(unit.kilojoule_per_mole / unit.angstrom).flatten(), dtype=np.float64)\n",
    "        self.memory_of_energy.append(E)\n",
    "        return E.value_in_unit(unit.kilojoule_per_mole), F_flat\n",
    "\n",
    "    def calculate_energy(self, x: unit.Quantity):\n",
    "        \"\"\"\n",
    "        Given a coordinate set (x) the energy is calculated in kJ/mol.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : array of floats, unit'd (angstroms)\n",
    "            initial configuration\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        energy : unit.quantity.Quantity\n",
    "            energy in kJ/mol\n",
    "        \"\"\"\n",
    "\n",
    "        #assert (type(x) == unit.quantity.Quantity)\n",
    "        coordinates = torch.tensor([x.value_in_unit(unit.angstroms)],\n",
    "                                   requires_grad=True, device=self.device, dtype=torch.float32)\n",
    "\n",
    "        energy_in_hartrees = self._calculate_energy(coordinates)\n",
    "        energy = energy_in_hartrees.item() * self.hartree_to_kJ_per_mole * unit.kilojoule_per_mole\n",
    "        return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integrator(OMMLI):\n",
    "    def __init__(self,\n",
    "                 temperature=300.0 * unit.kelvin,\n",
    "                 collision_rate=1.0 / unit.picoseconds,\n",
    "                 timestep=1.0 * unit.femtoseconds,\n",
    "                 splitting=\"V R O R F\",\n",
    "                 constraint_tolerance=1e-6,\n",
    "                 **kwargs):\n",
    "        \"\"\"Create a Langevin integrator with the prescribed operator splitting.\n",
    "\n",
    "        arguments\n",
    "            splitting : string, default: \"V R O R\"\n",
    "                Sequence of \"R\", \"V\", \"O\" (and optionally \"{\", \"}\", \"V0\", \"V1\", ...) substeps to be executed each timestep.\n",
    "                Forces are only used in V-step. Handle multiple force groups by appending the force group index\n",
    "                to V-steps, e.g. \"V0\" will only use forces from force group 0. \"V\" will perform a step using all forces.\n",
    "            temperature : np.unit.Quantity compatible with kelvin, default: 300.0*unit.kelvin\n",
    "               Fictitious \"bath\" temperature\n",
    "            collision_rate : np.unit.Quantity compatible with 1/picoseconds, default: 1.0/unit.picoseconds\n",
    "               Collision rate\n",
    "            timestep : np.unit.Quantity compatible with femtoseconds, default: 1.0*unit.femtoseconds\n",
    "               Integration timestep\n",
    "            constraint_tolerance : float, default: 1.0e-8\n",
    "                Tolerance for constraint solver\n",
    "        \"\"\"\n",
    "        #just super our previous method\n",
    "        super().__init__(temperature,\n",
    "                         collision_rate,\n",
    "                         timestep,\n",
    "                         splitting,\n",
    "                         constraint_tolerance,\n",
    "                         **kwargs)\n",
    "        \n",
    "\n",
    "    def _add_V_step(self, force_group=\"0\"):\n",
    "        \"\"\"Deterministic velocity update, using only forces from force-group fg.\n",
    "\n",
    "        arguments\n",
    "            force_group : str, optional, default=\"0\"\n",
    "               Force group to use for this step\n",
    "        \"\"\"\n",
    "        self.addComputeSum(\"old_ke\", self._kinetic_energy)\n",
    "\n",
    "        # update velocities\n",
    "        if self._mts:\n",
    "            self.addComputePerDof(\"v\", \"v + ((dt / {}) * moddi / m)\".format(self._force_group_nV[force_group], force_group))\n",
    "        else:\n",
    "            self.addComputePerDof(\"v\", \"v + (dt / {}) * moddi / m\".format(self._force_group_nV[\"0\"]))\n",
    "\n",
    "        self.addConstrainVelocities()\n",
    "\n",
    "\n",
    "        self.addComputeSum(\"new_ke\", self._kinetic_energy)\n",
    "        self.addComputeGlobal(\"shadow_work\", \"shadow_work + (new_ke - old_ke)\")\n",
    "    \n",
    "    def _add_F_step(self):\n",
    "        \"\"\"\n",
    "        add an moddi update step\n",
    "        \"\"\"\n",
    "        self.addComputePerDof('moddi', 'f')\n",
    "        \n",
    "    \n",
    "    def _add_variables(self):\n",
    "        super()._add_variables()\n",
    "        self.addPerDofVariable('moddi', 0)\n",
    "    \n",
    "    def _add_integrator_steps(self):\n",
    "        \"\"\"\n",
    "        Add the steps to the integrator--this can be overridden to place steps around the integration.\n",
    "        \"\"\"\n",
    "        super()._add_integrator_steps()\n",
    "        #self.addUpdateContextState()\n",
    "    \n",
    "    @property\n",
    "    def _step_dispatch_table(self):\n",
    "        dispatch_table = super()._step_dispatch_table\n",
    "        dispatch_table['F'] = (self._add_F_step, False) #add a moddi variable\n",
    "        return dispatch_table\n",
    "        \n",
    "    \n",
    "class Propagator(OMMBIP):\n",
    "    def __init__(self,\n",
    "                 openmm_pdf_state,\n",
    "                 openmm_pdf_state_subset,\n",
    "                 subset_indices_map,\n",
    "                 integrator,\n",
    "                 ani_handler,\n",
    "                 context_cache=None,\n",
    "                 reassign_velocities=True,\n",
    "                 n_restart_attempts=0,\n",
    "                 reporter = None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        arguments\n",
    "            openmm_pdf_state : openmmtools.states.ThermodynamicState\n",
    "                the pdf state of the propagator\n",
    "            openmm_pdf_state_subset : openmmtools.states.ThermodynamicState\n",
    "                the pdf state of the atom subset\n",
    "            subset_indices_map : dict\n",
    "                dict of {openmm_pdf_state atom_index : openmm_pdf_state_subset atom index}\n",
    "            integrator : openmm.Integrator\n",
    "                integrator of dynamics\n",
    "            ani_handler : ANI1_force_and_energy\n",
    "                handler for ani forces and potential energy\n",
    "            context_cache : openmmtools.cache.ContextCache, optional\n",
    "                The ContextCache to use for Context creation. If None, the global cache\n",
    "                openmmtools.cache.global_context_cache is used (default is None).\n",
    "            reassign_velocities : bool, optional\n",
    "                If True, the velocities will be reassigned from the Maxwell-Boltzmann\n",
    "                distribution at the beginning of the move (default is False).\n",
    "            n_restart_attempts : int, optional\n",
    "                When greater than 0, if after the integration there are NaNs in energies,\n",
    "                the move will restart. When the integrator has a random component, this\n",
    "                may help recovering. On the last attempt, the ``Context`` is\n",
    "                re-initialized in a slower process, but better than the simulation\n",
    "                crashing. An IntegratorMoveError is raised after the given number of\n",
    "                attempts if there are still NaNs. \n",
    "            reporter : coddiwomple.openmm.reporter.OpenMMReporter, default None\n",
    "                a reporter object to write trajectories\n",
    "        \"\"\"\n",
    "        super().__init__(openmm_pdf_state,\n",
    "                 integrator,\n",
    "                 context_cache,\n",
    "                 reassign_velocities,\n",
    "                 n_restart_attempts)\n",
    "        #create a pdf state for the subset indices (usually a vacuum system)\n",
    "        self.pdf_state_subset = openmm_pdf_state_subset\n",
    "        assert self.pdf_state_subset.temperature == self.pdf_state.temperature, f\"the temperatures of the pdf states do not match\"\n",
    "        \n",
    "        #create a dictionary for subset indices\n",
    "        self._subset_indices_map = subset_indices_map\n",
    "        \n",
    "        #create an ani handler attribute that can be referenced\n",
    "        self.ani_handler = ani_handler\n",
    "        \n",
    "        #create a context for the subset atoms that can be referenced\n",
    "        self.context_subset, _ = cache.global_context_cache.get_context(self.pdf_state_subset)\n",
    "        \n",
    "        #create a reporter for the accumulated works\n",
    "        self._state_works = {}\n",
    "        self._state_works_counter = 0\n",
    "        \n",
    "        #create a reporter\n",
    "        self._write_trajectory = False if reporter is None else True\n",
    "        self.reporter=reporter\n",
    "        if self._write_trajectory:\n",
    "            from coddiwomple.particles import Particle\n",
    "            self.particle = Particle(0)\n",
    "        else:\n",
    "            self.particle = None\n",
    "        \n",
    "    def _before_integration(self, *args, **kwargs):\n",
    "        particle_state = args[0] #define the particle state\n",
    "        n_iterations = args[1] #define the number of iterations\n",
    "        \n",
    "        self._current_state_works = [] #define an interim (auxiliary) list that will track the thermodynamic work of the current application\n",
    "        self._current_state_works.append(0.0) #the first incremental work is always 0 since the importance function is identical to the first target distribution (i.e. fully interacting MM)\n",
    "        \n",
    "        self._iteration = 0.0 #define the first iteration as 0\n",
    "        self._n_iterations = n_iterations #the number of iterations in the protocol is equal to the number of steps in the application\n",
    "        \n",
    "        #update the particle state and the particle state subset\n",
    "        particle_state.update_from_context(self.context, ignore_velocities=True) #update the particle state from the context\n",
    "        self.particle_state_subset = SamplerState(positions = particle_state.positions[list(self._subset_indices_map.keys())]) #create a particle state from the subset context\n",
    "        self.particle_state_subset.apply_to_context(self.context_subset, ignore_velocities=True) #apply the subset particle state to its context\n",
    "        self.particle_state_subset.update_from_context(self.context_subset, ignore_velocities=True) #update the subset particle state from its context to updated the potential energy\n",
    "        #print(f\"particle subset reduced potential: {self.pdf_state_subset.reduced_potential(self.particle_state_subset)}\")\n",
    "           \n",
    "        #get the reduced potential\n",
    "        reduced_potential = self._compute_hybrid_potential(_lambda = self._iteration / self._n_iterations, particle_state = particle_state)\n",
    "        perturbed_reduced_potential = self._compute_hybrid_potential(_lambda = (self._iteration + 1.0) / self._n_iterations, particle_state = particle_state)\n",
    "        self._current_state_works.append(self._current_state_works[-1] + (perturbed_reduced_potential - reduced_potential))\n",
    "        #print(f\"reduced_potential: {reduced_potential}; perturbed_potential: {perturbed_reduced_potential}\")\n",
    "        \n",
    "        #make a new force object\n",
    "        mm_force_matrix = self._compute_hybrid_forces(_lambda = (self._iteration + 1.0) / self._n_iterations, particle_state = particle_state).value_in_unit_system(unit.md_unit_system)\n",
    "        self.integrator.setPerDofVariableByName('moddi', mm_force_matrix) \n",
    "        \n",
    "        #report\n",
    "        if self._write_trajectory:\n",
    "            self.particle.update_state(particle_state)\n",
    "            self.reporter.record([self.particle])\n",
    "        \n",
    "        #logger\n",
    "        #self._log_context_parameters()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _during_integration(self, *args, **kwargs):\n",
    "        particle_state = args[0]\n",
    "        self._iteration += 1.0\n",
    "        \n",
    "        \n",
    "        #update the particle state and the particle state subset\n",
    "        particle_state.update_from_context(self.context, ignore_velocities=True) #update the particle state from the context\n",
    "        self.particle_state_subset.positions = particle_state.positions[list(self._subset_indices_map.keys())] #update the particle subset positions appropriately\n",
    "        self.particle_state_subset.apply_to_context(self.context_subset, ignore_velocities=True) #apply the subset particle state to its context\n",
    "        self.particle_state_subset.update_from_context(self.context_subset, ignore_velocities=True) #update the subset particle state from its context to updated the potential energy\n",
    "        \n",
    "        #get the reduced potential\n",
    "        if self._iteration < self._n_iterations:\n",
    "            reduced_potential = self._compute_hybrid_potential(_lambda = self._iteration / self._n_iterations, particle_state = particle_state)\n",
    "            perturbed_reduced_potential = self._compute_hybrid_potential(_lambda = (self._iteration + 1.0) / self._n_iterations, particle_state = particle_state)\n",
    "            self._current_state_works.append(self._current_state_works[-1] + (perturbed_reduced_potential - reduced_potential))\n",
    "            \n",
    "            #and create a new modified force\n",
    "            mm_force_matrix = self._compute_hybrid_forces(_lambda = (self._iteration + 1.0) / self._n_iterations, particle_state = particle_state).value_in_unit_system(unit.md_unit_system)\n",
    "            self.integrator.setPerDofVariableByName('moddi', mm_force_matrix) \n",
    "        else:\n",
    "            #we are done\n",
    "            pass\n",
    "        \n",
    "        if self._write_trajectory:\n",
    "            self.particle.update_state(particle_state)\n",
    "            if self._iteration == self._n_iterations:\n",
    "                self.reporter.record([self.particle], save_to_disk=True)\n",
    "            else:\n",
    "                self.reporter.record([self.particle], save_to_disk=False)\n",
    "        \n",
    "        #logger\n",
    "        #self._log_context_parameters()\n",
    "            \n",
    "            \n",
    "        \n",
    "    def _after_integration(self, *args, **kwargs):\n",
    "        self._state_works[self._state_works_counter] = deepcopy(self._current_state_works)\n",
    "        self._state_works_counter += 1\n",
    "        \n",
    "        if self._write_trajectory:\n",
    "            self.reporter.reset()\n",
    "        #self._log_context_parameters()\n",
    "        \n",
    "\n",
    "    def _compute_hybrid_potential(self,_lambda, particle_state):\n",
    "        \"\"\"\n",
    "        function to compute the hybrid reduced potential defined as follows:\n",
    "        U(x_rec, x_lig) = u_mm,rec(x_rec) - lambda*u_mm,lig(x_lig) + lambda*u_ani,lig(x_lig)\n",
    "        \"\"\"\n",
    "        reduced_potential = (self.pdf_state.reduced_potential(particle_state)\n",
    "                             - _lambda * self.pdf_state_subset.reduced_potential(self.particle_state_subset)\n",
    "                             + _lambda * self.ani_handler.calculate_energy(self.particle_state_subset.positions) * self.pdf_state.beta)\n",
    "        return reduced_potential\n",
    "    \n",
    "    def _compute_hybrid_forces(self, _lambda, particle_state):\n",
    "        \"\"\"\n",
    "        function to compute a hybrid force matrix of shape num_particles x 3\n",
    "        in the spirit of the _compute_hybrid_potential, we compute the forces in the following way\n",
    "            F(x_rec, x_lig) = F_mm(x_rec, x_lig) - lambda * F_mm(x_lig) + lambda * F_ani(x_lig)\n",
    "        \"\"\"\n",
    "        # get the complex mm forces\n",
    "        state = self.context.getState(getForces=True)\n",
    "        mm_force_matrix = state.getForces(asNumpy=True)\n",
    "\n",
    "        # get the ligand mm forces\n",
    "        subset_state = self.context_subset.getState(getForces=True)\n",
    "        mm_force_matrix_subset = subset_state.getForces(asNumpy=True)\n",
    "\n",
    "        # get the ligand ani forces\n",
    "        coords = self.particle_state_subset.positions\n",
    "        subset_ani_force_matrix, energie = self.ani_handler.calculate_force(coords)\n",
    "\n",
    "        # now combine the ligand forces\n",
    "        subset_force_matrix = _lambda * (subset_ani_force_matrix - mm_force_matrix_subset)\n",
    "\n",
    "        # and append to the complex forces...\n",
    "        mm_force_matrix[list(self._subset_indices_map.keys()), :] += subset_force_matrix\n",
    "\n",
    "        return mm_force_matrix\n",
    "\n",
    "    def _get_context_subset_parameters(self):\n",
    "        \"\"\"\n",
    "        return a dictionary of the self.context_subset's parameters\n",
    "\n",
    "        returns\n",
    "            context_parameters : dict\n",
    "            {parameter name <str> : parameter value value <float>}\n",
    "        \"\"\"\n",
    "        swig_parameters = self.context_subset.getParameters()\n",
    "        context_parameters = {q: swig_parameters[q] for q in swig_parameters}\n",
    "        return context_parameters\n",
    "    \n",
    "    def _log_context_parameters(self):\n",
    "        \"\"\"\n",
    "        log the context and context subset parameters\n",
    "        \"\"\"\n",
    "        context_parameters = self._get_context_parameters()\n",
    "        context_subset_parameters = self._get_context_subset_parameters()\n",
    "        _logger.debug(f\"\\tcontext_parameters during integration:\")\n",
    "        for key, val in context_parameters.items():\n",
    "            _logger.debug(f\"\\t\\t{key}: {val}\")\n",
    "        \n",
    "        _logger.debug(f\"\\tcontext subset parameters during integration:\")\n",
    "        for key, val in context_subset_parameters:\n",
    "            _logger.debug(f\"\\t\\t{key}: {val}\")\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def state_works(self):\n",
    "        return self._state_works      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annealed_importance_sampling(system,\n",
    "                                 system_subset,\n",
    "                                 subset_indices_map,\n",
    "                                 endstate_cache_filename,\n",
    "                                 directory_name,\n",
    "                                 trajectory_prefix,\n",
    "                                 md_topology,\n",
    "                                 number_of_applications,\n",
    "                                 steps_per_application,\n",
    "                                 integrator_kwargs = {'temperature': 300.0 * unit.kelvin,\n",
    "                                                      'collision_rate': 1.0 / unit.picoseconds,\n",
    "                                                      'timestep': 1.0 * unit.femtoseconds,\n",
    "                                                      'splitting': \"V R O R F\",\n",
    "                                                      'constraint_tolerance': 1e-6,\n",
    "                                                      'pressure': 1.0 * unit.atmosphere},\n",
    "                                 save_indices = None,\n",
    "                                 position_extractor = None\n",
    "                                ):\n",
    "    \"\"\"\n",
    "    conduct annealed importance sampling in the openmm regime\n",
    "\n",
    "    arguments\n",
    "        system : openmm.System\n",
    "            system\n",
    "        system_subset : openmm.System\n",
    "            subset system\n",
    "        subset_indices_map : dict\n",
    "            dict of {openmm_pdf_state atom_index : openmm_pdf_state_subset atom index}\n",
    "        endstate_cache_filename : str\n",
    "            path to the endstate cache pdb\n",
    "        directory_name : str\n",
    "            directory that will be written to\n",
    "        trajectory_prefix : str\n",
    "            .pdb prefix\n",
    "        md_topology : mdtraj.Topology\n",
    "            topology that will write the trajectory\n",
    "        save_indices : list\n",
    "            list of indices that will be saved \n",
    "        number_of_applications : int\n",
    "            number of applications of the propagator\n",
    "        steps_per_application : int\n",
    "            number of integration steps per application\n",
    "        integrator_kwargs : dict, see default\n",
    "            kwargs to pass to OMMLIAIS integrator\n",
    "        save_indices : list(int)\n",
    "            list of indices of md_topology atoms to save to disk\n",
    "        position_extractor : function, default None\n",
    "            function to extract appropriate positons from the cache\n",
    "    \"\"\"\n",
    "    from coddiwomple.particles import Particle\n",
    "    from coddiwomple.openmm.states import OpenMMParticleState, OpenMMPDFState\n",
    "    #load the endstate cache\n",
    "    traj = md.Trajectory.load(endstate_cache_filename)\n",
    "    num_frames = traj.n_frames\n",
    "    print(f\"loaded {num_frames} from the cache\")\n",
    "    \n",
    "    #make a handle object for ANI\n",
    "    species_str = ''.join([atom.element.symbol for atom in md_topology.subset(list(subset_indices_map.keys())).atoms])\n",
    "    print(f\"species string: {species_str}\")\n",
    "    ani_handler = ANI1_force_and_energy(model = torchani.models.ANI1ccx(),\n",
    "                                                 atoms=species_str,\n",
    "                                                 platform='cpu',\n",
    "                                                 temperature=integrator_kwargs['temperature'])\n",
    "\n",
    "    #make thermostates\n",
    "    pdf_state = ThermodynamicState(system = system, temperature = integrator_kwargs['temperature'], pressure= integrator_kwargs['pressure'])\n",
    "    pdf_state_subset = ThermodynamicState(system = system_subset, temperature = integrator_kwargs['temperature'], pressure = None)\n",
    "    \n",
    "    #make a reporter\n",
    "    reporter = OpenMMReporter(directory_name, trajectory_prefix, md_topology, subset_indices = save_indices)\n",
    "    \n",
    "    \n",
    "    #make an integrator\n",
    "    integrator = Integrator(**integrator_kwargs)\n",
    "    \n",
    "    #make a propagator\n",
    "    propagator = Propagator(openmm_pdf_state = pdf_state,\n",
    "                 openmm_pdf_state_subset = pdf_state_subset,\n",
    "                 subset_indices_map = subset_indices_map,\n",
    "                 integrator = integrator,\n",
    "                 ani_handler = ani_handler,\n",
    "                 context_cache=None,\n",
    "                 reassign_velocities=True,\n",
    "                 n_restart_attempts=0,\n",
    "                 reporter = reporter)\n",
    "\n",
    "    frames = np.random.choice(range(num_frames), number_of_applications)\n",
    "    particle = Particle(0)\n",
    "    \n",
    "    for i in tqdm.trange(number_of_applications):\n",
    "        if position_extractor is not None:\n",
    "            positions = position_extractor(traj.xyz[frames[i]] * unit.nanometers)\n",
    "        else:\n",
    "            positions = traj.xyz[frames[i]] * unit.nanometers\n",
    "        particle_state = OpenMMParticleState(positions = positions, box_vectors = traj.unitcell_vectors[frames[i]]*unit.nanometers)\n",
    "        particle.update_state(particle_state)\n",
    "        #try:\n",
    "        _, _return_dict = propagator.apply(particle_state, n_steps = steps_per_application, reset_integrator=True, apply_pdf_to_context=True)\n",
    "        #except Exception as e:\n",
    "        #    print(e)\n",
    "\n",
    "\n",
    "    return propagator.state_works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example calculation: let's do benzene --> methylbenzene\n",
    "from pkg_resources import resource_filename\n",
    "import pickle\n",
    "import mdtraj as md\n",
    "solvent_factory_filename = resource_filename('coddiwomple', f\"/data/perses_data/benzene_methylbenzene.solvent.factory.pkl\")\n",
    "vacuum_factory_filename = resource_filename('coddiwomple', f\"/data/perses_data/benzene_methylbenzene.vacuum.factory.pkl\")\n",
    "\n",
    "with open(solvent_factory_filename, 'rb') as f:\n",
    "    solvent_factory = pickle.load(f)\n",
    "\n",
    "with open(vacuum_factory_filename, 'rb') as f:\n",
    "    vacuum_factory = pickle.load(f)\n",
    "\n",
    "\n",
    "system = solvent_factory._topology_proposal._new_system\n",
    "system_subset = vacuum_factory._topology_proposal._new_system\n",
    "subset_indices_map = {i:j for i, j in zip(range(1119, 1134), range(15))} #map for one endstate 'anisole'\n",
    "endstate_cache_filename = '/mnt/c/Users/domin/github/codditest/1_endstate_cache/benzene_methylbenzene.solvent.0000.pdb'\n",
    "directory_name = 'methylbenzene_solvent'\n",
    "trajectory_prefix = 'troubleshoot'\n",
    "md_topology = md.Topology.from_openmm(solvent_factory._topology_proposal._new_topology)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Atom 1114 (H1) of chain 1 residue 371 (HOH)>,\n",
       " <Atom 1115 (H2) of chain 1 residue 371 (HOH)>,\n",
       " <Atom 1116 (O) of chain 1 residue 372 (HOH)>,\n",
       " <Atom 1117 (H1) of chain 1 residue 372 (HOH)>,\n",
       " <Atom 1118 (H2) of chain 1 residue 372 (HOH)>,\n",
       " <Atom 1119 (C5) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1120 (C4) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1121 (C6) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1122 (C3) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1123 (C7) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1124 (C2) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1125 (C1) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1126 (H6) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1127 (H5) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1128 (H7) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1129 (H4) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1130 (H8) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1131 (H1) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1132 (H2) of chain 2 residue 373 (MOL)>,\n",
       " <Atom 1133 (H3) of chain 2 residue 373 (MOL)>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(solvent_factory._topology_proposal._new_topology.atoms())[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Atom 0 (C5) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 1 (C4) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 2 (C6) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 3 (C3) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 4 (C7) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 5 (C2) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 6 (C1) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 7 (H6) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 8 (H5) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 9 (H7) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 10 (H4) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 11 (H8) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 12 (H1) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 13 (H2) of chain 1 residue 0 (MOL)>,\n",
       " <Atom 14 (H3) of chain 1 residue 0 (MOL)>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vacuum_factory._topology_proposal._new_topology.atoms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 87 from the cache\n",
      "species string: CCCCCCCHHHHHHHH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openmm_reporters:creating trajectory storage object...\n",
      "DEBUG:openmm_propagators:initializing Integrator...\n",
      "DEBUG:openmm_propagators:Integrator: metropolization is False\n",
      "DEBUG:openmm_propagators:Integrator: successfully parsed splitting string\n",
      "DEBUG:openmm_propagators:Integrator: adding global variables...\n",
      "DEBUG:openmm_propagators:Integrator: adding integrator steps...\n",
      "DEBUG:openmm_propagators:Integrator: adding substep functions...\n",
      "DEBUG:openmm_propagators:successfully executed ABCMeta init.\n",
      "DEBUG:openmm_propagators:successfully equipped integrator: Integrator\n",
      "DEBUG:openmm_propagators:integrator printable: None\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 1/50 [00:00<00:06,  8.03it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step      0 : allow forces to update the context state\n",
      "step      1 : if(has_kT_changed = 1):\n",
      "step      2 :    sigma <- sqrt(kT/m)\n",
      "step      3 :    has_kT_changed <- 0\n",
      "step      4 : end\n",
      "step      5 : old_ke <- sum(0.5 * m * v * v)\n",
      "step      6 : v <- v + (dt / 1) * moddi / m\n",
      "step      7 : constrain velocities\n",
      "step      8 : new_ke <- sum(0.5 * m * v * v)\n",
      "step      9 : shadow_work <- shadow_work + (new_ke - old_ke)\n",
      "step     10 : old_pe <- energy\n",
      "step     11 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     12 : x <- x + ((dt / 2) * v)\n",
      "step     13 : x1 <- x\n",
      "step     14 : constrain positions\n",
      "step     15 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     16 : constrain velocities\n",
      "step     17 : new_pe <- energy\n",
      "step     18 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     19 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     20 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     21 : v <- (a * v) + (b * sigma * gaussian)\n",
      "step     22 : constrain velocities\n",
      "step     23 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     24 : proposal_work <- proposal_work + -1*(new_ke - old_ke)\n",
      "step     25 : old_pe <- energy\n",
      "step     26 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     27 : x <- x + ((dt / 2) * v)\n",
      "step     28 : x1 <- x\n",
      "step     29 : constrain positions\n",
      "step     30 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     31 : constrain velocities\n",
      "step     32 : new_pe <- energy\n",
      "step     33 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     34 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     35 : moddi <- f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  4%|▍         | 2/50 [00:00<00:05,  8.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/50 [00:00<00:05,  7.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/50 [00:00<00:05,  8.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 5/50 [00:00<00:05,  8.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/50 [00:00<00:05,  8.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 7/50 [00:00<00:05,  8.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/50 [00:00<00:05,  8.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/50 [00:01<00:04,  8.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 10/50 [00:01<00:04,  8.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 11/50 [00:01<00:04,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 12/50 [00:01<00:04,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 13/50 [00:01<00:04,  8.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 14/50 [00:01<00:04,  8.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 15/50 [00:01<00:04,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16/50 [00:01<00:04,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 17/50 [00:02<00:03,  8.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 18/50 [00:02<00:03,  8.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 19/50 [00:02<00:03,  7.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 20/50 [00:02<00:03,  8.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 21/50 [00:02<00:03,  8.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 22/50 [00:02<00:03,  8.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 23/50 [00:02<00:03,  8.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 24/50 [00:02<00:03,  8.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 25/50 [00:03<00:03,  8.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 26/50 [00:03<00:02,  8.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 27/50 [00:03<00:02,  8.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 28/50 [00:03<00:02,  8.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 29/50 [00:03<00:02,  8.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 30/50 [00:03<00:02,  8.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 31/50 [00:03<00:02,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 32/50 [00:03<00:02,  8.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 33/50 [00:03<00:02,  8.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 34/50 [00:04<00:01,  8.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 35/50 [00:04<00:01,  8.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 36/50 [00:04<00:01,  8.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 37/50 [00:04<00:01,  8.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 38/50 [00:04<00:01,  8.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 39/50 [00:04<00:01,  8.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 40/50 [00:04<00:01,  7.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 41/50 [00:04<00:01,  7.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 42/50 [00:05<00:01,  7.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 43/50 [00:05<00:00,  7.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 44/50 [00:05<00:00,  7.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 45/50 [00:05<00:00,  7.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 46/50 [00:05<00:00,  7.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 47/50 [00:05<00:00,  7.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 48/50 [00:05<00:00,  7.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49/50 [00:06<00:00,  7.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50/50 [00:06<00:00,  8.10it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "instantaneous_works = annealed_importance_sampling(system = system,\n",
    "                                 system_subset = system_subset,\n",
    "                                 subset_indices_map = subset_indices_map,\n",
    "                                 endstate_cache_filename = endstate_cache_filename,\n",
    "                                 directory_name = directory_name,\n",
    "                                 trajectory_prefix = trajectory_prefix,\n",
    "                                 md_topology = md_topology,\n",
    "                                 number_of_applications = 50,\n",
    "                                 steps_per_application = 1,\n",
    "                                 integrator_kwargs = {'temperature': 300.0 * unit.kelvin,\n",
    "                                                      'collision_rate': 1.0 / unit.picoseconds,\n",
    "                                                      'timestep': 1.0 * unit.femtoseconds,\n",
    "                                                      'splitting': \"V R O R F\",\n",
    "                                                      'constraint_tolerance': 1e-6,\n",
    "                                                      'pressure': 1.0 * unit.atmosphere},\n",
    "                                 save_indices = None,\n",
    "                                 position_extractor = solvent_factory.new_positions\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 87 from the cache\n",
      "species string: CCCCCCCHHHHHHHH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openmm_reporters:creating trajectory storage object...\n",
      "DEBUG:openmm_propagators:initializing Integrator...\n",
      "DEBUG:openmm_propagators:Integrator: metropolization is False\n",
      "DEBUG:openmm_propagators:Integrator: successfully parsed splitting string\n",
      "DEBUG:openmm_propagators:Integrator: adding global variables...\n",
      "DEBUG:openmm_propagators:Integrator: adding integrator steps...\n",
      "DEBUG:openmm_propagators:Integrator: adding substep functions...\n",
      "DEBUG:openmm_propagators:successfully executed ABCMeta init.\n",
      "DEBUG:openmm_propagators:successfully equipped integrator: Integrator\n",
      "DEBUG:openmm_propagators:integrator printable: None\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step      0 : allow forces to update the context state\n",
      "step      1 : if(has_kT_changed = 1):\n",
      "step      2 :    sigma <- sqrt(kT/m)\n",
      "step      3 :    has_kT_changed <- 0\n",
      "step      4 : end\n",
      "step      5 : old_ke <- sum(0.5 * m * v * v)\n",
      "step      6 : v <- v + (dt / 1) * moddi / m\n",
      "step      7 : constrain velocities\n",
      "step      8 : new_ke <- sum(0.5 * m * v * v)\n",
      "step      9 : shadow_work <- shadow_work + (new_ke - old_ke)\n",
      "step     10 : old_pe <- energy\n",
      "step     11 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     12 : x <- x + ((dt / 2) * v)\n",
      "step     13 : x1 <- x\n",
      "step     14 : constrain positions\n",
      "step     15 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     16 : constrain velocities\n",
      "step     17 : new_pe <- energy\n",
      "step     18 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     19 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     20 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     21 : v <- (a * v) + (b * sigma * gaussian)\n",
      "step     22 : constrain velocities\n",
      "step     23 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     24 : proposal_work <- proposal_work + -1*(new_ke - old_ke)\n",
      "step     25 : old_pe <- energy\n",
      "step     26 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     27 : x <- x + ((dt / 2) * v)\n",
      "step     28 : x1 <- x\n",
      "step     29 : constrain positions\n",
      "step     30 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     31 : constrain velocities\n",
      "step     32 : new_pe <- energy\n",
      "step     33 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     34 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     35 : moddi <- f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|▏         | 1/50 [00:00<00:33,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/50 [00:01<00:32,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/50 [00:01<00:30,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/50 [00:02<00:29,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 5/50 [00:03<00:28,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/50 [00:03<00:28,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 7/50 [00:04<00:27,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/50 [00:05<00:26,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/50 [00:05<00:26,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 10/50 [00:06<00:26,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 11/50 [00:07<00:25,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 12/50 [00:07<00:24,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 13/50 [00:08<00:24,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 14/50 [00:09<00:23,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 15/50 [00:09<00:23,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16/50 [00:10<00:23,  1.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 17/50 [00:11<00:22,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 18/50 [00:11<00:22,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 19/50 [00:12<00:21,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 20/50 [00:13<00:20,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 21/50 [00:13<00:19,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 22/50 [00:14<00:18,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 23/50 [00:15<00:18,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 24/50 [00:15<00:17,  1.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 25/50 [00:16<00:16,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 26/50 [00:17<00:16,  1.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 27/50 [00:18<00:16,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 28/50 [00:18<00:15,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 29/50 [00:19<00:14,  1.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 30/50 [00:20<00:13,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 31/50 [00:20<00:13,  1.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 32/50 [00:21<00:13,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 33/50 [00:22<00:12,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 34/50 [00:23<00:12,  1.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 35/50 [00:24<00:11,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 36/50 [00:24<00:10,  1.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 37/50 [00:25<00:09,  1.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 38/50 [00:26<00:08,  1.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 39/50 [00:26<00:07,  1.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 40/50 [00:27<00:06,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 41/50 [00:28<00:06,  1.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 42/50 [00:28<00:05,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 43/50 [00:29<00:04,  1.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 44/50 [00:30<00:03,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 45/50 [00:30<00:03,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 46/50 [00:31<00:02,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 47/50 [00:31<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 48/50 [00:32<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49/50 [00:33<00:00,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50/50 [00:34<00:00,  1.47it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "zehn_iteration_works = annealed_importance_sampling(system = system,\n",
    "                                 system_subset = system_subset,\n",
    "                                 subset_indices_map = subset_indices_map,\n",
    "                                 endstate_cache_filename = endstate_cache_filename,\n",
    "                                 directory_name = directory_name,\n",
    "                                 trajectory_prefix = trajectory_prefix,\n",
    "                                 md_topology = md_topology,\n",
    "                                 number_of_applications = 50,\n",
    "                                 steps_per_application = 10,\n",
    "                                 integrator_kwargs = {'temperature': 300.0 * unit.kelvin,\n",
    "                                                      'collision_rate': 1.0 / unit.picoseconds,\n",
    "                                                      'timestep': 1.0 * unit.femtoseconds,\n",
    "                                                      'splitting': \"V R O R F\",\n",
    "                                                      'constraint_tolerance': 1e-6,\n",
    "                                                      'pressure': 1.0 * unit.atmosphere},\n",
    "                                 save_indices = None,\n",
    "                                 position_extractor = solvent_factory.new_positions\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 87 from the cache\n",
      "species string: CCCCCCCHHHHHHHH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openmm_reporters:creating trajectory storage object...\n",
      "DEBUG:openmm_propagators:initializing Integrator...\n",
      "DEBUG:openmm_propagators:Integrator: metropolization is False\n",
      "DEBUG:openmm_propagators:Integrator: successfully parsed splitting string\n",
      "DEBUG:openmm_propagators:Integrator: adding global variables...\n",
      "DEBUG:openmm_propagators:Integrator: adding integrator steps...\n",
      "DEBUG:openmm_propagators:Integrator: adding substep functions...\n",
      "DEBUG:openmm_propagators:successfully executed ABCMeta init.\n",
      "DEBUG:openmm_propagators:successfully equipped integrator: Integrator\n",
      "DEBUG:openmm_propagators:integrator printable: None\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step      0 : allow forces to update the context state\n",
      "step      1 : if(has_kT_changed = 1):\n",
      "step      2 :    sigma <- sqrt(kT/m)\n",
      "step      3 :    has_kT_changed <- 0\n",
      "step      4 : end\n",
      "step      5 : old_ke <- sum(0.5 * m * v * v)\n",
      "step      6 : v <- v + (dt / 1) * moddi / m\n",
      "step      7 : constrain velocities\n",
      "step      8 : new_ke <- sum(0.5 * m * v * v)\n",
      "step      9 : shadow_work <- shadow_work + (new_ke - old_ke)\n",
      "step     10 : old_pe <- energy\n",
      "step     11 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     12 : x <- x + ((dt / 2) * v)\n",
      "step     13 : x1 <- x\n",
      "step     14 : constrain positions\n",
      "step     15 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     16 : constrain velocities\n",
      "step     17 : new_pe <- energy\n",
      "step     18 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     19 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     20 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     21 : v <- (a * v) + (b * sigma * gaussian)\n",
      "step     22 : constrain velocities\n",
      "step     23 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     24 : proposal_work <- proposal_work + -1*(new_ke - old_ke)\n",
      "step     25 : old_pe <- energy\n",
      "step     26 : old_ke <- sum(0.5 * m * v * v)\n",
      "step     27 : x <- x + ((dt / 2) * v)\n",
      "step     28 : x1 <- x\n",
      "step     29 : constrain positions\n",
      "step     30 : v <- v + ((x - x1) / (dt / 2))\n",
      "step     31 : constrain velocities\n",
      "step     32 : new_pe <- energy\n",
      "step     33 : new_ke <- sum(0.5 * m * v * v)\n",
      "step     34 : shadow_work <- shadow_work + (new_ke + new_pe) - (old_ke + old_pe)\n",
      "step     35 : moddi <- f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  2%|▏         | 1/50 [00:03<02:38,  3.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 2/50 [00:06<02:34,  3.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 3/50 [00:09<02:27,  3.14s/it]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 4/50 [00:12<02:21,  3.09s/it]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 5/50 [00:15<02:22,  3.16s/it]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 6/50 [00:18<02:20,  3.19s/it]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 7/50 [00:22<02:23,  3.33s/it]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 8/50 [00:26<02:25,  3.47s/it]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 9/50 [00:29<02:21,  3.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 10/50 [00:33<02:17,  3.44s/it]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 11/50 [00:36<02:13,  3.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 12/50 [00:39<02:08,  3.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 13/50 [00:43<02:06,  3.43s/it]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 14/50 [00:46<02:02,  3.41s/it]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 15/50 [00:50<02:07,  3.64s/it]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 16/50 [00:56<02:20,  4.14s/it]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 17/50 [01:05<03:03,  5.56s/it]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 18/50 [01:13<03:24,  6.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 19/50 [01:17<02:56,  5.70s/it]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 20/50 [01:21<02:36,  5.21s/it]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 21/50 [01:25<02:18,  4.79s/it]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 22/50 [01:29<02:09,  4.63s/it]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 23/50 [01:33<01:55,  4.29s/it]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 24/50 [01:36<01:45,  4.04s/it]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 25/50 [01:40<01:38,  3.93s/it]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 26/50 [01:43<01:31,  3.80s/it]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 27/50 [01:47<01:25,  3.73s/it]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 28/50 [01:50<01:21,  3.69s/it]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 29/50 [01:54<01:18,  3.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 30/50 [01:58<01:16,  3.81s/it]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 31/50 [02:02<01:11,  3.74s/it]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 32/50 [02:05<01:05,  3.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 33/50 [02:09<01:02,  3.65s/it]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 34/50 [02:12<00:57,  3.61s/it]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 35/50 [02:16<00:54,  3.66s/it]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 36/50 [02:21<00:53,  3.85s/it]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 37/50 [02:25<00:52,  4.05s/it]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 38/50 [02:29<00:49,  4.15s/it]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 39/50 [02:34<00:46,  4.22s/it]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 40/50 [02:38<00:43,  4.37s/it]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 41/50 [02:43<00:40,  4.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 42/50 [02:48<00:36,  4.54s/it]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 43/50 [02:52<00:30,  4.38s/it]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 44/50 [02:56<00:25,  4.23s/it]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 45/50 [03:00<00:20,  4.11s/it]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 46/50 [03:03<00:15,  3.99s/it]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 47/50 [03:07<00:11,  3.90s/it]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 48/50 [03:11<00:07,  3.96s/it]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 49/50 [03:15<00:03,  3.94s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 50/50 [03:20<00:00,  4.01s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "funfzig_iteration_works = annealed_importance_sampling(system = system,\n",
    "                                 system_subset = system_subset,\n",
    "                                 subset_indices_map = subset_indices_map,\n",
    "                                 endstate_cache_filename = endstate_cache_filename,\n",
    "                                 directory_name = directory_name,\n",
    "                                 trajectory_prefix = trajectory_prefix,\n",
    "                                 md_topology = md_topology,\n",
    "                                 number_of_applications = 50,\n",
    "                                 steps_per_application = 50,\n",
    "                                 integrator_kwargs = {'temperature': 300.0 * unit.kelvin,\n",
    "                                                      'collision_rate': 1.0 / unit.picoseconds,\n",
    "                                                      'timestep': 1.0 * unit.femtoseconds,\n",
    "                                                      'splitting': \"V R O R F\",\n",
    "                                                      'constraint_tolerance': 1e-6,\n",
    "                                                      'pressure': 1.0 * unit.atmosphere},\n",
    "                                 save_indices = None,\n",
    "                                 position_extractor = solvent_factory.new_positions\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Energie Verteilung')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0.\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans.ttf) normal normal 400 normal>) = 0.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif Display' (DejaVuSerifDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmr10' (cmr10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBolIta.ttf) italic normal bold normal>) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Bold.ttf) normal normal bold normal>) = 0.33499999999999996\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmss10' (cmss10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUni.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Oblique.ttf) oblique normal 400 normal>) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-Bold.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneral.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymReg.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Mono' (DejaVuSansMono-BoldOblique.ttf) oblique normal bold normal>) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-Oblique.ttf) oblique normal 400 normal>) = 1.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmmi10' (cmmi10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmtt10' (cmtt10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans Display' (DejaVuSansDisplay.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXNonUnicode' (STIXNonUniIta.ttf) italic normal 400 normal>) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymReg.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFourSym' (STIXSizFourSymBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralBolIta.ttf) italic normal bold normal>) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeTwoSym' (STIXSizTwoSymReg.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeFiveSym' (STIXSizFiveSymReg.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Sans' (DejaVuSans-BoldOblique.ttf) oblique normal bold normal>) = 1.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Bold.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmb10' (cmb10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-BoldItalic.ttf) italic normal bold normal>) = 11.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'DejaVu Serif' (DejaVuSerif-Italic.ttf) italic normal 400 normal>) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmex10' (cmex10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'cmsy10' (cmsy10.ttf) normal normal 400 normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeThreeSym' (STIXSizThreeSymReg.ttf) normal normal regular normal>) = 10.05\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXSizeOneSym' (STIXSizOneSymBol.ttf) normal normal bold normal>) = 10.335\n",
      "DEBUG:matplotlib.font_manager:findfont: score(<Font 'STIXGeneral' (STIXGeneralItalic.ttf) italic normal 400 normal>) = 11.05\n",
      "DEBUG:matplotlib.font_manager:findfont: Matching :family=sans-serif:style=normal:variant=normal:weight=normal:stretch=normal:size=12.0 to DejaVu Sans ('/home/dominic/anaconda3/envs/openmm/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/ttf/DejaVuSans.ttf') with score of 0.050000.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inst_works = [val[-1] for val in instantaneous_works.values()]\n",
    "plt.hist(inst_works)\n",
    "\n",
    "_zehn_works = [val[-1] for val in zehn_iteration_works.values()]\n",
    "plt.hist(_zehn_works)\n",
    "\n",
    "_funfzig_works = [val[-1] for val in funfzig_iteration_works.values()]\n",
    "plt.hist(_funfzig_works)\n",
    "plt.xlabel(f\"energie (kT)\")\n",
    "plt.ylabel(f\"frequenz\")\n",
    "plt.title(f\"Energie Verteilung\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
